{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1b1uAGluUjy"
      },
      "source": [
        "# Investments-Selected Quantitative Tools Project\n",
        "Monna Dimitrova \\\n",
        "Áron Miklós \\\n",
        "Konrad Ochędzan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af9EnAxyuxAt"
      },
      "source": [
        "## Getting, cleaning and transforming data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (0.2.63)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (0.11.3)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (6.31.1)\n",
            "Requirement already satisfied: websockets>=13.0 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from curl_cffi>=0.7->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: pycparser in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Collecting pandas_datareader\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting lxml (from pandas_datareader)\n",
            "  Downloading lxml-5.4.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pandas>=0.23 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas_datareader) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas_datareader) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/volatilityenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas_datareader) (1.17.0)\n",
            "Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "Downloading lxml-5.4.0-cp310-cp310-macosx_10_9_universal2.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lxml, pandas_datareader\n",
            "Successfully installed lxml-5.4.0 pandas_datareader-0.10.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install yfinance\n",
        "!{sys.executable} -m pip install pandas_datareader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Pv32r0jku5iu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from pandas_datareader import data as pdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qg2_Y2oPwOnm"
      },
      "outputs": [],
      "source": [
        "os.environ['FRED_API_KEY'] = '99e90ae628f35ef304441e83d7bf85cf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A73EmPLXwqFl"
      },
      "source": [
        "Function to fetch daily close prices for an equity/index/ETF using Yahoo Finance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6jtYtIVjwcPm"
      },
      "outputs": [],
      "source": [
        "def fetch_prices(ticker: str, start_date: str, end_date: str) -> pd.Series:\n",
        "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
        "  price_series = price_df['Close']\n",
        "  clean_name = ticker.replace('^', '')\n",
        "  price_series.name = clean_name\n",
        "  return price_series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTyGwqxKxJz7"
      },
      "source": [
        "Function to fetch data from FRED like rates, macro data, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iUZFSERjxZDU"
      },
      "outputs": [],
      "source": [
        "def fetch_fred_data(id: str, start_date: str, end_date: str) -> pd.Series:\n",
        "  raw_data = pdr.DataReader(id, 'fred', start_date, end_date)\n",
        "  if isinstance(raw_data, pd.Series):\n",
        "    fred_series = raw_data\n",
        "  else:\n",
        "    fred_series = raw_data.iloc[:, 0]\n",
        "  return fred_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz6dbdPTxovB",
        "outputId": "c547b9c1-f38b-4f56-ac45-984b58f5c530"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/var/folders/dj/1rbmtvsd08g_1g5crh6jhk080000gn/T/ipykernel_83046/1939872230.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  price_df = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "START_DATE = '2009-01-01'\n",
        "END_DATE = '2025-06-15'\n",
        "\n",
        "# S&P 500 index\n",
        "sp500 = fetch_prices('^GSPC', START_DATE, END_DATE)\n",
        "sp500.rename(columns={'^GSPC': 'sp500'}, inplace=True)\n",
        "\n",
        "# VIX implied volatility index\n",
        "vix = fetch_prices('^VIX', START_DATE, END_DATE)\n",
        "vix.rename(columns={'^VIX': 'vix'}, inplace=True)\n",
        "\n",
        "# Treasury yields\n",
        "tbill3m = fetch_fred_data('TB3MS', START_DATE, END_DATE)\n",
        "yield2y = fetch_fred_data('DGS2', START_DATE, END_DATE)\n",
        "yield10y = fetch_fred_data('DGS10', START_DATE, END_DATE)\n",
        "\n",
        "# Foreign indices\n",
        "nikkei = fetch_prices('^N225', START_DATE, END_DATE)\n",
        "nikkei.rename(columns={'^N225': 'nikkei'}, inplace=True)\n",
        "ftse = fetch_prices('^FTSE', START_DATE, END_DATE)\n",
        "ftse.rename(columns={'^FTSE': 'ftse'}, inplace=True)\n",
        "hsi = fetch_prices('^HSI', START_DATE, END_DATE)\n",
        "hsi.rename(columns={'^HSI': 'hsi'}, inplace=True)\n",
        "\n",
        "# Commodities\n",
        "\n",
        "crude = fetch_prices('CL=F', START_DATE, END_DATE)\n",
        "crude.rename(columns={'CL=F': 'crude'}, inplace=True)\n",
        "\n",
        "gold = fetch_prices('GC=F', START_DATE, END_DATE)\n",
        "gold.rename(columns={'GC=F': 'gold'}, inplace=True)\n",
        "\n",
        "silver = fetch_prices('SI=F', START_DATE, END_DATE)\n",
        "silver.rename(columns={'SI=F': 'silver'}, inplace=True)\n",
        "\n",
        "copper = fetch_prices('HG=F', START_DATE, END_DATE)\n",
        "copper.rename(columns={'HG=F': 'copper'}, inplace=True)\n",
        "\n",
        "gas = fetch_prices('NG=F', START_DATE, END_DATE)\n",
        "gas.rename(columns={'NG=F': 'gas'}, inplace=True)\n",
        "\n",
        "# Currencies \n",
        "\n",
        "eurusd = fetch_prices('EURUSD=X', START_DATE, END_DATE)\n",
        "eurusd.rename(columns={'EURUSD=X': 'eurusd'}, inplace=True)\n",
        "\n",
        "yenusd = fetch_prices('JPY=X', START_DATE, END_DATE)\n",
        "yenusd.rename(columns={'JPY=X': 'yenusd'}, inplace=True)\n",
        "\n",
        "yuanusd = fetch_prices('CNY=X', START_DATE, END_DATE)\n",
        "yuanusd.rename(columns={'CNY=X': 'yuanusd'}, inplace=True)\n",
        "\n",
        "cadusd = fetch_prices('CAD=X', START_DATE, END_DATE)\n",
        "cadusd.rename(columns={'CAD=X': 'cadusd'}, inplace=True)\n",
        "\n",
        "gbpusd = fetch_prices('GBP=X', START_DATE, END_DATE)\n",
        "gbpusd.rename(columns={'GBP=X': 'gbpusd'}, inplace=True)\n",
        "\n",
        "chfusd = fetch_prices('CHF=X', START_DATE, END_DATE)\n",
        "chfusd.rename(columns={'CHF=X': 'chfusd'}, inplace=True)\n",
        "\n",
        "# Macro factors, here we have monhtly data, we will forward fill later\n",
        "# Unemployment rate\n",
        "unemployment = fetch_fred_data('UNRATE', START_DATE, END_DATE)\n",
        "# CPI (Consumer Price Index)\n",
        "cpi = fetch_fred_data('CPIAUCSL', START_DATE, END_DATE)\n",
        "\n",
        "returns = sp500.pct_change()\n",
        "term_spread = (yield10y - yield2y)\n",
        "term_spread.rename('term_spread', inplace=True)\n",
        "\n",
        "# Combine all data into a single dataframe and make map correct names\n",
        "data = pd.concat([returns, vix, tbill3m, term_spread, nikkei, ftse, hsi, crude,gold,silver,gas,eurusd,yenusd,yuanusd,cadusd,gbpusd,chfusd,unemployment, cpi], axis=1).sort_index()\n",
        "column_mapping = {\n",
        "    'sp500': 'returns',\n",
        "    'vix': 'vix',\n",
        "    'TB3MS': 'tbill3m',\n",
        "    'term_spread': 'term_spread',\n",
        "    'UNRATE': 'unemployment',\n",
        "    'nikkei':'nikkei', \n",
        "    'ftse':'ftse',\n",
        "    'hsi':'hsi', \n",
        "    'crude':'crude',\n",
        "    'gold':'gold',\n",
        "    'silver':'silver',\n",
        "    'gas':'gas',\n",
        "    'eurusd':'eurusd',\n",
        "    'yenusd':'yenusd',\n",
        "    'yuanusd':'yuanusd',\n",
        "    'cadusd':'cadusd',\n",
        "    'gbpusd':'gbpusd',\n",
        "    'chfusd':'chfusd',\n",
        "    'CPIAUCSL': 'cpi'\n",
        "}\n",
        "data = data.rename(columns=column_mapping)\n",
        "\n",
        "# Forward-fill and backward-fill to transform to daily data,\n",
        "# drop NaN values\n",
        "# These are published daily, but we want to avoid missing rows due to missing data\n",
        "data[['vix', 'tbill3m', 'term_spread','nikkei', 'ftse', 'hsi', 'crude','gold','silver','gas','eurusd','yenusd','yuanusd','cadusd','gbpusd','chfusd']] = data[['vix', 'tbill3m', 'term_spread','nikkei', 'ftse', 'hsi', 'crude','gold','silver','gas','eurusd','yenusd','yuanusd','cadusd','gbpusd','chfusd']].ffill()\n",
        "# These macro factors are monthly we go to daily data\n",
        "data[['unemployment', 'cpi']] = data[['unemployment', 'cpi']].ffill().bfill()\n",
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoOacUZ1_ktN",
        "outputId": "f57472d2-87cd-4aef-f945-b0fa8943e62e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['returns', 'vix', 'tbill3m', 'term_spread', 'nikkei', 'ftse', 'hsi',\n",
            "       'crude', 'gold', 'silver', 'gas', 'eurusd', 'yenusd', 'yuanusd',\n",
            "       'cadusd', 'gbpusd', 'chfusd', 'unemployment', 'cpi'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv('data_non_std.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOKYLcHir6dI"
      },
      "source": [
        "Now we standardize the data. This means removing the mean and scaling to unit variance. Standardization is useful, because many machine learning estimators do not behave well if the individual features do not look similar to standard normally distributed data. \\\n",
        "We also compute realized volatility and split the data into training, validation and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CzFDcfOEsb4F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuyRTZ1KsyUn"
      },
      "outputs": [],
      "source": [
        "# Compute realized volatility: We use a 21 day rolling window to calculate\n",
        "# standard deviation of daily returns. Then we annualize it\n",
        "data['realized_vol'] = data['returns'].rolling(window=21).std() * np.sqrt(252)\n",
        "# remove NaNs (that is first 20 entries for which we cannot calculate it)\n",
        "data = data.dropna(subset=['realized_vol'])\n",
        "\n",
        "#Split by date: we train on past data, validate on more recent data and test on\n",
        "# the newest data\n",
        "split1 = '2016-01-01'\n",
        "split2 = '2019-01-01'\n",
        "\n",
        "train = data.loc[:split1].copy()\n",
        "validate = data.loc[split1:split2].copy()\n",
        "test = data.loc[split2:].copy()\n",
        "\n",
        "# Standardize features, we fit only on training set to avoid looking into the\n",
        "# future\n",
        "feature_cols = ['vix', 'tbill3m', 'term_spread','nikkei', 'ftse', 'hsi', 'crude','gold','silver','gas','eurusd','yenusd','yuanusd','cadusd','gbpusd','chfusd', 'unemployment', 'cpi']\n",
        "scaler = StandardScaler()\n",
        "train[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
        "validate[feature_cols] = scaler.transform(validate[feature_cols])\n",
        "test[feature_cols] = scaler.transform(test[feature_cols])\n",
        "\n",
        "# Label rows with its split\n",
        "train['split'] = 'train'\n",
        "validate['split'] = 'validate'\n",
        "test['split'] = 'test'\n",
        "\n",
        "# Combine all data into a single dataframe\n",
        "full_data = pd.concat([train, validate, test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxZQeHL7sfla",
        "outputId": "6bea55ab-f71f-499e-f8de-b3923a55517e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             returns       vix    tbill3m  term_spread  unemployment  \\\n",
            "2009-02-03  0.015834  3.059095   3.713323    -0.226714      0.310523   \n",
            "2009-02-04 -0.007490  3.163283   3.713323    -0.143517      0.310523   \n",
            "2009-02-05  0.016366  3.147457   3.713323    -0.143517      0.310523   \n",
            "2009-02-06  0.026896  3.099979   3.713323     0.043678      0.310523   \n",
            "2009-02-09  0.001485  3.135587   3.713323    -0.039520      0.310523   \n",
            "...              ...       ...        ...          ...           ...   \n",
            "2025-06-09  0.000920 -0.356694  70.483724    -3.242625     -2.300866   \n",
            "2025-06-10  0.005483 -0.384390  70.483724    -3.284224     -2.300866   \n",
            "2025-06-11 -0.002744 -0.343506  70.483724    -3.263425     -2.300866   \n",
            "2025-06-12  0.003822 -0.243274  70.483724    -3.284224     -2.300866   \n",
            "2025-06-13 -0.011296  0.126000  70.483724    -3.305024     -2.300866   \n",
            "\n",
            "                  cpi  realized_vol  split  \n",
            "2009-02-03  -1.855722      2.490922  train  \n",
            "2009-02-04  -1.855722      2.492364  train  \n",
            "2009-02-05  -1.855722      2.550253  train  \n",
            "2009-02-06  -1.855722      2.585917  train  \n",
            "2009-02-09  -1.855722      2.582677  train  \n",
            "...               ...           ...    ...  \n",
            "2025-06-09  11.325966     -0.001659   test  \n",
            "2025-06-10  11.325966     -0.005202   test  \n",
            "2025-06-11  11.325966     -0.490127   test  \n",
            "2025-06-12  11.325966     -0.508487   test  \n",
            "2025-06-13  11.325966     -0.413746   test  \n",
            "\n",
            "[4117 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "print(full_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CDvwsv3tzx4"
      },
      "source": [
        "## Neural network models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znS_y5BBuJBQ"
      },
      "source": [
        "Our goal is to decompose return prediction into two economic components: stochastic volatility and interest rate. Stochastic volatility captures the predictability of future variance while the interest rate reflects the effects of the specific term structure. Then we will use a mixture of these two components, using weights and scaling by microeconomic factors (unemployment, CPI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SumpjOMqvIHy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wNbxhhvvVHF"
      },
      "source": [
        "### Volatility agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6yVtvm1vPqT"
      },
      "outputs": [],
      "source": [
        "class VolAgent(nn.Module):\n",
        "  def __init__(self, input_size: int, hidden_size: int = 64, num_layers: int = 2,\n",
        "               dropout: float = 0.1) -> None:\n",
        "    super().__init__()\n",
        "    # We use LSTM to encode the volatility signals\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                        dropout=dropout)\n",
        "    # Linear layer to map the last hidden state to scalar\n",
        "    self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, input_features: Tensor) -> Tensor:\n",
        "    _, (hidden_states, _) = self.lstm(input_features)\n",
        "    last_hidden = hidden_states[-1]\n",
        "    predicted_vol_return = self.fc(last_hidden)\n",
        "    return predicted_vol_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhxAX_LMyGDf"
      },
      "source": [
        "## Interest rate agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMl-ULbTxGCb"
      },
      "outputs": [],
      "source": [
        "class InterestRateAgent(nn.Module):\n",
        "  def __init__(self, input_size: int, hidden_units: list[int] = [64, 32],\n",
        "               dropout: float = 0.1) -> None:\n",
        "    super().__init__()\n",
        "    layers = []\n",
        "    input_dimension = input_size\n",
        "    for layer_size in hidden_units:\n",
        "      layers.extend([nn.Linear(input_dimension, layer_size), nn.ReLU(), nn.Dropout(dropout)])\n",
        "      input_dimension = layer_size\n",
        "    layers.append(nn.Linear(input_dimension, 1))\n",
        "    self.net = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, input_features: Tensor) -> Tensor:\n",
        "    predicted_rate_return = self.net(input_features)\n",
        "    return predicted_rate_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmpL7Ecp0ZKb"
      },
      "source": [
        "## Weighting network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8w5iohV0a8_"
      },
      "source": [
        "This networks learns how to allocate weights between the volatility and interest rate agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SojTKKC05wX"
      },
      "outputs": [],
      "source": [
        "class WeightingNetwork(nn.Module):\n",
        "  def __init__(self, input_size: int, hidden_size: int = 32) -> None:\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, 2)\n",
        "\n",
        "  def forward(self, input_features: Tensor) -> Tensor:\n",
        "    hidden = F.relu(self.fc1(input_features))\n",
        "    raw_weights = self.fc2(hidden)\n",
        "    weights = F.softmax(raw_weights, dim=1)\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqFbMRof8IYs"
      },
      "source": [
        "## Macroeconomic scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d355p1iv8Nel"
      },
      "source": [
        "This is a network that uses the macroeconomic factors to scale the combined signal coming from the two agents. It calculates a multiplier that determines whether to have a larger or smaller leverage, meaning an amplified or dampened signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmomppsW8awM"
      },
      "outputs": [],
      "source": [
        "class MacroScaler(nn.Module):\n",
        "  def __init__(self, input_size: int) -> None:\n",
        "    super().__init__()\n",
        "    # Bias set to true: output = Wx + b, where b is the learned bias\n",
        "    self.linear = nn.Linear(input_size, 1, bias=True)\n",
        "\n",
        "    def forward(self, input_features: Tensor) -> Tensor:\n",
        "      raw_leverage = 1 + self.linear(input_features)\n",
        "      constrained_leverage = torch.tanh(raw_leverage)\n",
        "      return constrained_leverage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvZ89UlbDHXo"
      },
      "source": [
        "## Mixture agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJLcRifoDLIP"
      },
      "source": [
        "The mixture agent combines the volatility and interest rate agents using the weighting and scaling networks defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWqF2CPkDmCw"
      },
      "outputs": [],
      "source": [
        "class MixtureAgent(nn.Module):\n",
        "  def __init__(self, vol_input_size: int, interest_rate_input_size: int,\n",
        "               weight_input_size: int, macro_input_size: int,\n",
        "               vol_params: dict[str, object] = {},\n",
        "               interest_rate_params: dict[str, object] = {}) -> None:\n",
        "    super().__init__()\n",
        "    self.vol_agent = VolAgent(vol_input_size, **vol_params)\n",
        "    self.interest_rate_agent = InterestRateAgent(interest_rate_input_size, **interest_rate_params)\n",
        "    self.weights = WeightingNetwork(weight_input_size)\n",
        "    self.macro = MacroScaler(macro_input_size)\n",
        "\n",
        "  def forward(self, vol_input: Tensor, interest_rate_input: Tensor,\n",
        "              weights_input: Tensor, macro_input: Tensor) -> Tensor:\n",
        "    predicted_vol_return = self.vol_agent(vol_input)\n",
        "    predicted_interest_rate_return = self.interest_rate_agent(interest_rate_input)\n",
        "    weights = self.weights(weights_input)\n",
        "    macro = self.macro(macro_input)\n",
        "    combined_returns = weights[:, :1] * predicted_vol_return + weights[:, 1:] * predicted_interest_rate_return\n",
        "    scaled_returns = combined_returns * macro\n",
        "    return scaled_returns.squeeze()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (volatilityenv)",
      "language": "python",
      "name": "volatilityenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
